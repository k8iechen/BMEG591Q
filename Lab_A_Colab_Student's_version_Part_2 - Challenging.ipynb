{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3YKPONuSiVj"
   },
   "source": [
    "# BMEG 400Q-591Q : Lab A - Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoPkml17UCQn"
   },
   "source": [
    "---\n",
    "### Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3SoPviJUAga",
    "outputId": "7c5ab180-da13-4d98-c33e-5caaa3b8a8d6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VjT81NTBGPG"
   },
   "source": [
    "\n",
    "The dataset is available at the following link: [Dataset Link](https://drive.google.com/drive/folders/1OqOCUgEXKyadnhC10tbh8Jb1c6g0YgXW?usp=drive_link).\n",
    "you can create a shortcut in your Google Drive, then you can find it in '/content/drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS07ImfiSiWc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZgJeNvCSiWd"
   },
   "source": [
    "### **Part B: MRI Imaging and Reconstruction from K-space**\n",
    "\n",
    "##### Introduction: MRI Imaging and K-space\n",
    "Magnetic Resonance Imaging (MRI) is a powerful technique for capturing detailed anatomical and physiological information. Unlike X-ray or CT, MRI does not use ionizing radiation, making it safer for long-term or repeated use. However, **MRI images are not captured directly**; instead, they are acquired in **K-space**, a complex frequency domain representation.\n",
    "\n",
    "In this section, you will explore how MRI images are **reconstructed from K-space data** using techniques like the **Inverse Fast Fourier Transform (IFFT)**. Understanding the relationship between K-space and the final MRI image is critical for interpreting MRI scans and improving imaging quality.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuZEleM4SiWe"
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGDy712XSiWf"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWgfQsWTSiWf"
   },
   "source": [
    "Read the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Gc7j1F-SiWg"
   },
   "outputs": [],
   "source": [
    "file_name = '/content/drive/MyDrive/Data/MRI/kspace_only.h5'\n",
    "hf = h5py.File(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5tizXr4SiWh"
   },
   "source": [
    "File Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dramYNo8SiWi",
    "outputId": "4da321f1-603f-4ea2-b081-a655ca0e114b"
   },
   "outputs": [],
   "source": [
    "print('Keys:', list(hf.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP0n2b0wSiWm"
   },
   "source": [
    "##### Visualizing MRI Data from Multiple Coils\n",
    "\n",
    "##### What are Coils in MRI?\n",
    "In MRI imaging, **radiofrequency (RF) coils** are used to transmit and receive signals from different regions of the body. Modern MRI machines use **multiple coils** (known as phased-array coils) to improve **signal reception** and provide better spatial coverage. Each coil captures data from a specific region, and combining data from these coils helps in constructing high-quality images.\n",
    "\n",
    "In this part of the assignment, you will visualize slices of K-space data from **different coils** to understand the role each coil plays. The outputs will give you insight into how individual coils contribute to the overall MRI image.\n",
    "\n",
    "---\n",
    "\n",
    "##### Why Use the Log of the Absolute Values?\n",
    "K-space data contains **complex-valued signals** that encode both the frequency and phase information. To **visualize this data**, we need to convert the complex numbers into **magnitudes** using the **absolute value**.\n",
    "\n",
    "However, the range of magnitudes in K-space can vary widely, making it difficult to visualize the data directly. To make the data more interpretable, we apply a **logarithmic transformation** to compress the range of values and make smaller details more visible.  \n",
    "\n",
    "The following function is used to prepare the K-space data for visualization:\n",
    "$$\n",
    "MRI_{image} = \\log (|k\\text{-space}| + 10^{-9})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkxLw8qyT50q"
   },
   "source": [
    "---\n",
    "Write a Python code to visualize a slice of the K-Space of 3 different coils\n",
    "\n",
    "hint: for the log_abs function, you may need [np.log](https://numpy.org/doc/stable/reference/generated/numpy.log.html) and [np.abs](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrt0g1g9SiWm"
   },
   "outputs": [],
   "source": [
    "def show_coils(data, coils_num, cmap='gray'):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "    for i, num in enumerate(coils_num):\n",
    "        plt.subplot(1, len(coils_num), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Coil {num}')\n",
    "\n",
    "def log_abs(k_space_slice):\n",
    "    \"\"\"\n",
    "    A function that takes a k_space slice and return the log abs version of it\n",
    "    \"\"\"\n",
    "    return #TO DO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "YwxDFLEt93tZ",
    "outputId": "043a314f-0be7-4ca9-8fee-110be95dbb8e"
   },
   "outputs": [],
   "source": [
    "\n",
    "volume_kspace = hf['kspace'][()]\n",
    "print(volume_kspace.dtype)\n",
    "print(volume_kspace.shape) # Shape No. of slices, number of coils, height, width\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the first slice from the volume_kspace, and visualize coils 0,5,10 using `show_coils` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_kspace= #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMLsfBn3SiWn"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfv6AqTKSiWn"
   },
   "source": [
    "#### **MRI Image Reconstruction: From K-space to Multi-Coil Combination**\n",
    "\n",
    "In MRI, raw data is collected in **K-space**, a frequency domain representation, rather than directly as an image. To generate the final image, we need to apply an **Inverse Fast Fourier Transform (IFFT)** to convert this data from the frequency domain back into the spatial domain. Additionally, MRI machines often use **multiple radiofrequency (RF) coils**, with each coil capturing signals from different regions of the body. Combining data from multiple coils improves the **Signal-to-Noise Ratio (SNR)** and provides better image quality.\n",
    "\n",
    "The primary goal of this section is to:\n",
    "1. **Perform IFFT with shifts** to ensure the correct spatial arrangement of the transformed data.\n",
    "2. **Extract and visualize the image components**, including magnitude, phase, real, and imaginary parts. Each component carries specific information that contributes to the overall image:\n",
    "   - **Magnitude**: Represents the signal intensity, often used for diagnostic imaging.\n",
    "   - **Phase**: Useful for phase-contrast imaging or advanced MRI techniques.\n",
    "   - **Real and Imaginary Components**: The foundation of complex-valued MRI data, necessary for accurate reconstruction.\n",
    "\n",
    "MRI data from individual coils needs to be combined to create a final image. One of the most effective methods for this is the **Root Sum of Squares (RSS)** method, which sums the squared magnitudes of the signals from all coils and takes the square root. This enhances the overall image by **maximizing SNR** and utilizing information from multiple coils.\n",
    "\n",
    "Finally, the reconstructed image will be the result of combining all coil data using the root-mean square **RSS method**, yielding a clearer, high-SNR image. This process demonstrates the importance of **multi-coil MRI** and how advanced reconstruction techniques are essential for high-quality imaging in clinical practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38BXJesCUYrO"
   },
   "source": [
    "---\n",
    "\n",
    "Write a Python code to re-construct the MRI Image from the K-space\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hint: you may need\n",
    "[numpy.fft.fftshift](https://numpy.org/doc/stable/reference/generated/numpy.fft.fftshift.html),\n",
    "[numpy.fft.ifftshift](https://numpy.org/doc/stable/reference/generated/numpy.fft.ifftshift.html),\n",
    "[numpy.fft.ifft2](https://numpy.org/doc/stable/reference/generated/numpy.fft.ifft2.html),\n",
    "and [np.abs](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0vf4uQwSiWo"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inverse_fft2_shift(kspace):\n",
    "\n",
    "    \"\"\"\n",
    "    **Implementing Inverse Fourier Transform with Shift**:\n",
    "    - The function `inverse_fft2_shift` takes raw k-space data as input and performs the following steps:\n",
    "        - **Prepare k-Space for Inverse FFT**: The `np.fft.ifftshift` function moves the zero-frequency component of k-space from the center to the top-left corner. This step ensures that the k-space data is correctly formatted for the 2D inverse Fourier Transform (`ifft2`), which expects the zero-frequency component at the top-left.\n",
    "\n",
    "        - **2D Inverse Fourier Transform**: The `np.fft.ifft2` function transforms the k-space data from the frequency domain back into the spatial domain, producing a complex-valued reconstructed image.\n",
    "\n",
    "        - **Recenter the Spatial Domain**: The `np.fft.fftshift` function moves the low-frequency components in the reconstructed image from the top-left corner back to the center of the image. This ensures the reconstructed image is in a format suitable for visualization, with the central intensity variations correctly positioned.\n",
    "\n",
    "        - **Normalization**: The `norm='ortho'` argument ensures the output is properly normalized, preserving intensity consistency between input and output data.\n",
    "    \"\"\"\n",
    "\n",
    "    return #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "d0Y0P0WO93tZ",
    "outputId": "4ddb3f07-0d1a-418b-dd29-27c5bb9476ac"
   },
   "outputs": [],
   "source": [
    "show_coils(np.abs(inverse_fft2_shift(slice_kspace)), [0, 5, 10], cmap='gray')  # This shows coils 0, 5 and 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLL9iJbdUs2u"
   },
   "source": [
    "Extract the magnitude, phase, real and imaginary components of the MRI image and visualize them\n",
    "\n",
    "hint: you may need [np.abs](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html), [np.angle](https://numpy.org/doc/stable/reference/generated/numpy.angle.html), [np.real](https://numpy.org/doc/stable/reference/generated/numpy.real.html) and [np.imag](https://numpy.org/doc/stable/reference/generated/numpy.imag.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4xQTOIoSiWo"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_data = inverse_fft2_shift(slice_kspace)\n",
    "# Extract the magnitude of the image data.\n",
    "magnitude_data = #TO DO\n",
    "\n",
    "# Extract the phase of the image data.\n",
    "phase_data = #TO DO\n",
    "\n",
    "# Separate out the real component of the image data.\n",
    "real_data = #TO DO\n",
    "\n",
    "# Separate out the imaginary component of the image data.\n",
    "imaginary_data = #TO DO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "cog0Scp093tZ",
    "outputId": "74d0910e-3788-4744-8371-cbb5e10d23ab"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(magnitude_data[0], cmap='gray')\n",
    "plt.title('Magnitude Image')  # Set the title here\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(phase_data[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Phase Image')  # Set the title here\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(real_data[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Real Component')  # Set the title here\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(imaginary_data[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Imaginary Component ')  # Set the title here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL6GoqzzU114"
   },
   "source": [
    "Combine the signal coming from all the coils and re-construct the MRI Image\n",
    "\n",
    "The `rss` function is used to combine multi-coil MRI data into a single magnitude image using the **Root Sum of Squares (RSS)** method. This approach is commonly used in MRI reconstruction to leverage the data from multiple coils for enhanced image quality.\n",
    "\n",
    "\n",
    "RSS = $\\sqrt{\\sum_{i=1}^{n} |x_i|^2}$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x_i$ represents each data point in the magnitude data\n",
    "* $n$ represents the total number of data points\n",
    "\n",
    "\n",
    "hint: you may need [np.sqrt](https://numpy.org/doc/stable/reference/generated/numpy.sqrt.html), [np.sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) and [np.abs](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-dyE2C8SiWp"
   },
   "outputs": [],
   "source": [
    "def rss(magnitude_data):\n",
    "    return #TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3L3j3au5SiWp"
   },
   "outputs": [],
   "source": [
    "# Combine multi-coil data using Root Sum of Squares (RSS) to create magnitude image\n",
    "magnitude_slice = rss(magnitude_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "6EKKqf69SiWp",
    "outputId": "74a40428-6c81-4c74-b706-ed873d6ea31b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(magnitude_slice,cmap='gray')\n",
    "plt.title(\"Reconstructed Image\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvsHEqU7SiWq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBf7QJ3JSiWq"
   },
   "source": [
    "#### Accelerated MRI Reconstruction using Random Masking in K-space\n",
    "\n",
    "MRI scans often require long acquisition times to collect the full range of frequency data (K-space). To speed up the scanning process, **accelerated MRI** techniques selectively sample only parts of K-space, reducing the amount of acquired data. This is achieved through **random masking**, which creates a sparse K-space that still captures enough information to reconstruct the image. However, this is a double-edge weapon as this comes with the challenge of maintaining image quality. The Masking can significantly decrease the image quality\n",
    "\n",
    "In this section, we use the **FastMRI library** to apply a random mask to K-space data and reconstruct the MRI Image.\n",
    "\n",
    "\n",
    "By masking K-space, we can significantly reduce the scan time, but the challenge remains in reconstructing high-quality images from incomplete data. This technique illustrates the **trade-offs between scan time and image quality** in modern MRI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyRdf1oWVseg"
   },
   "source": [
    "---\n",
    "\n",
    "### Applying High-Pass and Low-Pass Filters in k-Space\n",
    "\n",
    "#### **What are we doing?**\n",
    "\n",
    "1. **Understanding Filters in k-Space**:\n",
    "   - **High-Pass Filter**:\n",
    "     - Retains high-frequency components and removes low-frequency data (center of k-space).\n",
    "   - **Low-Pass Filter**:\n",
    "     - Retains low-frequency components and removes high-frequency data (outer parts of k-space).\n",
    "\n",
    "2. **Creating Masks**:\n",
    "   - A mask is created to selectively retain or remove specific frequency components:\n",
    "     - **Low-Pass Mask**: Retains the central region of k-space.\n",
    "     - **High-Pass Mask**: Removes the central region and retains the outer parts of k-space.\n",
    "\n",
    "3. **Reconstruction**:\n",
    "   - Apply the filters to k-space and reconstruct the images using the inverse Fourier Transform.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Compare the original image, the low-pass filtered image, and the high-pass filtered image to observe the effects of each filter.\n",
    "\n",
    "   hint: you may need [numpy.zeros](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bnc9c7Vz93ta"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply high-pass or low-pass filtering to all coils\n",
    "def apply_filter_to_coils(kspace, filter_type='low', cutoff_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Apply high-pass or low-pass filter to k-space data for all coils.\n",
    "\n",
    "    Args:\n",
    "        kspace (ndarray): The k-space data with shape (num_coils, height, width).\n",
    "            Each coil contains its own k-space data.\n",
    "        filter_type (str): Type of filter to apply. \n",
    "            Options are:\n",
    "                - 'low': Retain the low-frequency components (center of k-space).\n",
    "                - 'high': Retain the high-frequency components (remove the center of k-space).\n",
    "        cutoff_ratio (float): Determines the size of the region to retain or remove \n",
    "            from the center of the k-space. \n",
    "            For example, a cutoff_ratio of 0.3 will define a square region centered \n",
    "            around the midpoint that is 30% of the total height and width.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Filtered k-space data with the same shape as the input.\n",
    "            The output should have the filter applied to each coil.\n",
    "\n",
    "    Instructions:\n",
    "        1. Compute the center coordinates of the k-space (height and width).\n",
    "        2. Define the size of the filtering region based on the cutoff_ratio.\n",
    "        3. Create a 2D mask to either retain or remove the center region.\n",
    "        4. Apply the same mask to all coils in the k-space data.\n",
    "        5. Return the filtered k-space data.\n",
    "\n",
    "    \"\"\"\n",
    "    num_coils, H, W = #TODO\n",
    "    center_h, center_w = #TODO\n",
    "\n",
    "    # Create a mask for filtering\n",
    "    mask = #TODO\n",
    "    cutoff_h, cutoff_w = #TODO\n",
    "\n",
    "    if filter_type == 'low':\n",
    "        # Retain the center\n",
    "        mask[center_h - cutoff_h:center_h + cutoff_h, center_w - cutoff_w:center_w + cutoff_w] = #TODO\n",
    "    elif filter_type == 'high':\n",
    "        # Remove the center\n",
    "        mask[:center_h - cutoff_h, :] = #TODO\n",
    "        mask[center_h + cutoff_h:, :] = #TODO\n",
    "        mask[:, :center_w - cutoff_w] = #TODO\n",
    "        mask[:, center_w + cutoff_w:] = #TODO\n",
    "\n",
    "    # Apply the mask to all coils\n",
    "    filtered_kspace = #TODO\n",
    "    return filtered_kspace\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i9zhp94n93ta",
    "outputId": "399db857-6444-4c45-bf87-79614cdf7104"
   },
   "outputs": [],
   "source": [
    "# Apply filters to all coils\n",
    "low_pass_kspace = apply_filter_to_coils(slice_kspace, filter_type='low', cutoff_ratio=0.1)\n",
    "high_pass_kspace = apply_filter_to_coils(slice_kspace, filter_type='high', cutoff_ratio=0.2)\n",
    "\n",
    "# Reconstruct images for all coils and combine using RSS\n",
    "low_pass_images = np.abs(inverse_fft2_shift(low_pass_kspace))\n",
    "high_pass_images = np.abs(inverse_fft2_shift(high_pass_kspace))\n",
    "\n",
    "# Combine using RSS\n",
    "low_pass_image_rss = rss(low_pass_images)\n",
    "high_pass_image_rss = rss(high_pass_images)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Original image and k-space\n",
    "original_image_rss = rss(np.abs(inverse_fft2_shift(slice_kspace)))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.imshow(log_abs(slice_kspace[0]), cmap='gray')\n",
    "plt.title('Original K-Space (Coil 0)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.imshow(log_abs(slice_kspace[5]), cmap='gray')\n",
    "plt.title('Original K-Space (Coil 5)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.imshow(original_image_rss, cmap='gray')\n",
    "plt.title('Original Image (RSS)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Low-pass filtered image and k-space\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.imshow(log_abs(low_pass_kspace[0]), cmap='gray')\n",
    "plt.title('Low-Pass K-Space (Coil 0)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.imshow(log_abs(low_pass_kspace[5]), cmap='gray')\n",
    "plt.title('Low-Pass K-Space (Coil 5)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.imshow(low_pass_image_rss, cmap='gray')\n",
    "plt.title('Low-Pass Filtered Image (RSS)')\n",
    "plt.axis('off')\n",
    "\n",
    "# High-pass filtered image and k-space\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.imshow(log_abs(high_pass_kspace[0]), cmap='gray')\n",
    "plt.title('High-Pass K-Space (Coil 0)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.imshow(log_abs(high_pass_kspace[5]), cmap='gray')\n",
    "plt.title('High-Pass K-Space (Coil 5)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.imshow(high_pass_image_rss, cmap='gray')\n",
    "plt.title('High-Pass Filtered Image (RSS)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xulY7XpM93ta"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFcan4rG93ta"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVjQZCVqSiWz"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "<br> **Question 1:** What is the purpose of applying an Inverse Fast Fourier Transform (IFFT) in MRI reconstruction? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> **Question 2:** Why do we need to shift the K-space data during the IFFT process? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> **Question 3:** What information is captured in the real and imaginary components of MRI data? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> **Question 4:** What role does the Root Sum of Squares (RSS) method play in multi-coil MRI reconstruction? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> **Question 5:** What are the advantages and limitations of applying high-pass or low-pass filters in k-space? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> **Question 6:** Why is logarithmic scaling applied when visualizing K-space data? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> **Question 7:** What information is carried by the low-frequency and high-frequency components of K-space? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75M57lIiSiW0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQGHGwY4SiW1"
   },
   "source": [
    "### Functional MRI (fMRI):\n",
    "\n",
    "#### What is fMRI?\n",
    "**Functional Magnetic Resonance Imaging (fMRI)** is a non-invasive imaging technique that measures and maps brain activity by detecting changes in blood flow. Unlike conventional structural MRI, which captures anatomical images of the brain, fMRI focuses on **functional processes** by tracking the brain's activity in real-time. The underlying principle of fMRI is based on the **blood-oxygen-level-dependent (BOLD) signal**, which reflects the amount of oxygenated and deoxygenated hemoglobin in the blood.\n",
    "\n",
    "When a brain region becomes more active, it consumes more oxygen. In response, the body sends additional oxygenated blood to these active regions, leading to detectable changes in the magnetic properties of the blood. This allows fMRI to indirectly measure neuronal activity.\n",
    "\n",
    "---\n",
    "\n",
    "#### How Does fMRI Work?\n",
    "fMRI primarily relies on the **BOLD (Blood-Oxygen-Level-Dependent) signal** to detect brain activity. When neurons become active, the local oxygen demand increases, and more oxygenated blood is delivered to the area. The fMRI scanner measures this change in blood oxygenation levels to infer which parts of the brain are involved in a specific task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zm6_kPnLSiW3",
    "outputId": "7e759349-719e-45af-b8f7-9643e55818ad"
   },
   "outputs": [],
   "source": [
    "!pip install nilearn\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from nilearn import regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgGl59ZTX19J"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3um8IZxVSiW8"
   },
   "source": [
    "#### Working with fMRI Data: Haxby Dataset\n",
    "\n",
    "In this section, we will load and explore a popular fMRI dataset: the **Haxby Dataset**. This dataset contains both **anatomical MRI scans** and **functional MRI (fMRI) scans**, as well as metadata associated with the experimental conditions. We will use it to demonstrate how to load, inspect, and extract specific runs of fMRI data.\n",
    "\n",
    "The Haxby dataset is widely used in neuroscience research to investigate brain activity in response to visual stimuli, making it an excellent resource for learning how to handle fMRI data. Below, we outline each step of the process.\n",
    "\n",
    "The Haxby dataset divides the fMRI data into multiple runs (sessions). We extract the first run from the data by identifying which volumes belong to run 1 (indicated by chunks == 0 in the metadata).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "UjlwKpv4SiW9",
    "outputId": "abe1a3e7-5ef8-4480-fc93-45b34bdfbade"
   },
   "outputs": [],
   "source": [
    "data = datasets.fetch_haxby(\n",
    "    data_dir=None,\n",
    "    subjects=1,\n",
    "    fetch_stimuli=False,\n",
    "    verbose=1\n",
    ")\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4LCY8tDSiW-",
    "outputId": "d0311403-703d-440f-aae8-b54f8bfa0cc3"
   },
   "outputs": [],
   "source": [
    "print(data['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZT2RJFlBSiW_",
    "outputId": "090dda99-5c1c-4b02-91ef-a176fa02e7e1"
   },
   "outputs": [],
   "source": [
    "anat_img = image.load_img(data['anat'])\n",
    "print(\"Shape of Anatomical MRI image: %s\" % (anat_img.shape,))\n",
    "func_img = image.load_img(data['func'][0])\n",
    "print(\"Shape of functional MRI image: %s\" % (func_img.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVwwlJ3FSiXB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "rWYJKEvWSiXB",
    "outputId": "9de0cc98-972f-4891-c367-00e5fd75b3ad"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(data['session_target'][0], sep=' ')\n",
    "print(\"Shape of metadata dataframe: %s\" % (metadata.shape,), end='\\n\\n')\n",
    "metadata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtGPa-IPSiXC",
    "outputId": "e4f4d113-c909-4aac-8908-bf0da0cc3522"
   },
   "outputs": [],
   "source": [
    "nvol_run_1 = np.sum(metadata['chunks'] == 0)\n",
    "print(\"Number of volumes in run 1: %i\" % nvol_run_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oY6yGgJ3SiXD",
    "outputId": "1e864f3f-a9d4-41ea-f4ca-0939f6028abe"
   },
   "outputs": [],
   "source": [
    "to_index = np.arange(nvol_run_1, dtype=int)\n",
    "func_img_run1 = image.index_img(func_img, to_index)\n",
    "print(\"Shape of func_img_run1: %s\" % (func_img_run1.shape,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USdonuBjSiXD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL8FX0iiSiXD"
   },
   "source": [
    "#### Visualizing and Smoothing Functional MRI Data\n",
    "\n",
    "In this section, we load and explore the **functional MRI (fMRI) data**, apply **smoothing** to improve visualization, and project the fMRI data onto the brain surface for better spatial interpretation. These steps are essential in preparing the data for further analysis, ensuring that the visualized brain activity is clear, interpretable, and aligned with anatomical structures.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc1fmStPY-vL"
   },
   "source": [
    "Display the anatomy img (anat_img) using [plot_anat](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.plot_anat.html) and [view_img](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.view_img.html)\n",
    "\n",
    "note: for view_img don't forget to set bg_img=anat_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "YorSv2-MSiXE",
    "outputId": "57bd1f7b-9210-486d-dd15-9ffae9a16ae5"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "WEuj6NQOSiXF",
    "outputId": "152c3f0b-d36c-4100-ec1e-c27c252e2cb7"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGw2ECu2SiXF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGhcPmNMY4JD"
   },
   "source": [
    "Calculate the mean of the time signal coming from  func_img_run1 using [mean_img](https://nilearn.github.io/dev/modules/generated/nilearn.image.mean_img.html) and display it with [plot_epi](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.plot_epi.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "pQxucZEFY4-J",
    "outputId": "da743680-5c53-430d-97f0-c32181671f05"
   },
   "outputs": [],
   "source": [
    "#TO DO\n",
    "mean_img=#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATxhjvZmZ-Pk"
   },
   "source": [
    "Use [smooth_img](https://nilearn.github.io/stable/modules/generated/nilearn.image.smooth_img.html) to smooth the mean_img and visualize the filtered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "6oCBSvaASiXG",
    "outputId": "1e1a6cff-cc37-49cc-f936-1f9bff3b5b9e"
   },
   "outputs": [],
   "source": [
    "#TO DO\n",
    "tsnr_func_smooth = #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiG2tx1PbWTX"
   },
   "source": [
    "Use [view_img](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.view_img.html) to visualize the smoothed and anatomy images\n",
    "\n",
    "hint: set bg_img=tsnr_func_smooth parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "2RlJ-ms4a7Pd",
    "outputId": "67e40de0-d7a5-4ee1-a7f6-5d50665368ea"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9vlN1vObjk9"
   },
   "source": [
    "Apply a signal threshold to view_img\n",
    "\n",
    "hint: use threshold parameter in [view_img](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.view_img.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "etvKp6bmSiXJ",
    "outputId": "8de921e8-a606-490a-f2b9-214c94dec480"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bZUUW7USiXJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYYJVxKxSiXJ"
   },
   "source": [
    "#### Brain Connectivity Analysis with the Harvard-Oxford Atlas\n",
    "\n",
    "In this section, we explore the **Harvard-Oxford atlas** to study brain connectivity. We will load and visualize different regions of the brain using **maximum probability and probabilistic atlases**. Additionally, we will extract **region-of-interest (ROI) signals**, compute a **correlation matrix** between these signals, and visualize the **connectivity patterns** as both a matrix and a connectome.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw0FGCykfsXj"
   },
   "source": [
    "# Functional Connectivity Analysis Using ROI Signals\n",
    "\n",
    "This section focuses on extracting region of interest (ROI) signals from functional MRI (fMRI) data and computing the connectivity matrix using correlation analysis. The following steps outline the logic:\n",
    "\n",
    "## 1. Load the Harvard-Oxford Atlas\n",
    "- Fetch the Harvard-Oxford probabilistic atlas using `datasets.fetch_atlas_harvard_oxford`.\n",
    "- Load the atlas into memory as an image using `image.load_img`.\n",
    "\n",
    "## 2. Resample the Atlas\n",
    "- Resample the Harvard-Oxford atlas to match the resolution and dimensions of the functional MRI image (`func_img`) using `image.resample_to_img`.\n",
    "- Use nearest-neighbor interpolation to align the atlas with the target image.\n",
    "\n",
    "## 3. Extract ROI Signals\n",
    "- Use `regions.img_to_signals_labels` to extract average signals from the ROIs defined by the atlas.\n",
    "  - Inputs: Functional image (`func_img`) and resampled atlas (`ho_maxprob_atlas_img_resamp`).\n",
    "  - Outputs: ROI signals (`av_roi_signals`) and their corresponding labels (`roi_labels`).\n",
    "- Print the shape and type of the extracted signals for verification.\n",
    "\n",
    "## 4. Compute the Connectivity Matrix\n",
    "- Use the `ConnectivityMeasure` class from Nilearn to compute the functional connectivity matrix.\n",
    "- Specify the type of connectivity measure (e.g., correlation) and fit the ROI signals.\n",
    "\n",
    "\n",
    "## 5. Visualize the Connectivity Matrix\n",
    "- Compute the center coordinates of each region using `plotting.find_parcellation_cut_coords`.\n",
    "- Visualize the connectivity matrix as a connectome using `plotting.view_connectome`.\n",
    "  - Inputs: The connectivity matrix (`corr_mat`) and ROI coordinates (`coords`).\n",
    "  - Apply an edge threshold (e.g., \"95%\") to highlight the strongest connections.\n",
    "\n",
    "  \n",
    "\n",
    "This workflow allows for a clear understanding of the functional relationships between different brain regions, leveraging anatomical parcellation and connectivity measures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiVrkOhHSiXJ"
   },
   "source": [
    "### Task: Exploring the Harvard-Oxford Cortical Atlas\n",
    "\n",
    "In this section, you will:\n",
    "\n",
    "1. **Fetch the Harvard-Oxford Cortical Atlas**:\n",
    "   - Use `datasets.fetch_atlas_harvard_oxford` to load the cortical atlas with a specific threshold and resolution.\n",
    "   - Analyze the data structure and contents of the atlas using the `pprint` function.\n",
    "\n",
    "2. **Load and Inspect the Atlas Image**:\n",
    "   - Load the atlas image into a variable using `image.load_img`.\n",
    "   - Understand its dimensions and structure by printing its shape.\n",
    "\n",
    "3. **Count the Number of Regions**:\n",
    "   - Use `np.unique` to determine the unique region labels in the atlas.\n",
    "   - Print the total number of regions identified.\n",
    "\n",
    "4. **Identify a Specific Region**:\n",
    "   - Select a specific label (e.g., value `2`) and find its corresponding region name in the atlas.\n",
    "\n",
    "This exercise will help you familiarize yourself with the Harvard-Oxford atlas, a commonly used tool in fMRI analysis, and understand how to explore its structure programmatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEd8q4yCSiXK"
   },
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "Olo1ertTSiXK",
    "outputId": "4d8a8998-3624-484f-ab9d-43029bb907bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "ho_maxprob_atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xelARV-GSiXK",
    "outputId": "3d52d132-98f3-45c6-caac-b04181b7d730"
   },
   "outputs": [],
   "source": [
    "pprint(ho_maxprob_atlas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mowg-A2eSiXL",
    "outputId": "69d6164b-f467-40ad-88a4-683f0c4afdc7"
   },
   "outputs": [],
   "source": [
    "ho_maxprob_atlas_img = image.load_img(ho_maxprob_atlas['maps'])\n",
    "print(\"ho_maxprob_atlas_img is a 4D image with shape %s\" % (ho_maxprob_atlas_img.shape,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYQ_YrztSiXM"
   },
   "source": [
    "We extract the unique labels from the atlas and count the total number of regions. We also identify the brain region associated with a specific label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAmzFADRSiXM",
    "outputId": "154fc0b4-7255-4971-e58c-93b1027b93ec"
   },
   "outputs": [],
   "source": [
    "region_int_labels = np.unique(ho_maxprob_atlas_img.get_fdata())\n",
    "n_regions = region_int_labels.size\n",
    "\n",
    "print(\"There are %i different regions in the Harvard-Oxford cortical atlas!\" % n_regions)\n",
    "idx = 2\n",
    "region_with_value2 = ho_maxprob_atlas['labels'][idx]\n",
    "print(\"The region with value 2 is: %s\" % region_with_value2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W794LC68c4Ar"
   },
   "source": [
    "Use [plot_roi](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.plot_roi.html) to visualize the Atlas ( ho_maxprob_atlas_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "70yrHaHmSiXN",
    "outputId": "ea78807a-4c51-40e3-b10a-7ee32e684512"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t-4EO5hSiXN"
   },
   "source": [
    "### Task: Resampling and Extracting ROI Signals\n",
    "\n",
    "#### **What are we doing?**\n",
    "\n",
    "1. **Inspecting Image Dimensions**:\n",
    "   - We start by checking the shapes of the Harvard-Oxford atlas (`ho_maxprob_atlas_img`) and the functional MRI image (`func_img`).\n",
    "   - This step ensures we understand the differences in spatial resolutions and dimensions between these two datasets.\n",
    "\n",
    "2. **Resampling the Atlas Image**:\n",
    "   - The Harvard-Oxford atlas has a different resolution compared to the functional data. To use the atlas for region-specific analysis, we need to align (resample) its resolution to match that of the functional image.\n",
    "   - The `image.resample_to_img` function adjusts the atlas to the same grid as the functional data using the nearest-neighbor interpolation method. This ensures that each voxel in the atlas aligns with the functional data.\n",
    "\n",
    "3. **Extracting Region-Specific Signals**:\n",
    "   - After resampling, we extract average signals from the functional data for each region of interest (ROI) defined in the atlas. This is done using the `regions.img_to_signals_labels` function.\n",
    "   - Signals are aggregated over all voxels within each region, providing a single representative value for each ROI at each time point.\n",
    "\n",
    "4. **Exploring Extracted Signals**:\n",
    "   - Once the signals are extracted, we print their type and shape to verify that the process worked correctly. Additionally, we retrieve the corresponding labels to map these signals back to specific brain regions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why are we doing this?**\n",
    "\n",
    "1. **Aligning Data for Analysis**:\n",
    "   - Functional MRI data is often acquired at a different spatial resolution than anatomical or atlas data. Resampling aligns these datasets, allowing seamless analysis of functional activity in predefined anatomical regions.\n",
    "\n",
    "2. **Preparing Data for Connectivity Analysis**:\n",
    "   - Extracting average signals from ROIs is a necessary step before conducting connectivity analyses, which measure relationships between different brain regions.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMHCTEsASiXO",
    "outputId": "fdf7d3f9-c319-40fb-9edd-35499dd4a5bc"
   },
   "outputs": [],
   "source": [
    "print(ho_maxprob_atlas_img.shape,func_img_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1ukCYSjdMrG"
   },
   "source": [
    "Use [resample_to_img](https://nilearn.github.io/stable/modules/generated/nilearn.image.resample_to_img.html) to do the resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mu5W01RoSiXO",
    "outputId": "b58aaeb0-78ae-4535-e0c3-2b4e1ca47651"
   },
   "outputs": [],
   "source": [
    "#TO DO\n",
    "ho_maxprob_atlas_img_resamp = #TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhvnOCSmSiXO",
    "outputId": "b324068f-d8cb-4b6e-ec3a-cf9b82d7bc70"
   },
   "outputs": [],
   "source": [
    "print(ho_maxprob_atlas_img_resamp.shape,func_img_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoZdRDfgSiXP"
   },
   "source": [
    "We extract average signals from the regions defined by the atlas using [img_to_signals_labels](https://nilearn.github.io/stable/modules/generated/nilearn.regions.img_to_signals_labels.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vx_hvfyhSiXQ",
    "outputId": "0388a65b-cbb5-40d8-dbc5-48dc2f8907e6"
   },
   "outputs": [],
   "source": [
    "av_roi_data = regions.img_to_signals_labels(\n",
    "    func_img_run1,\n",
    "    labels_img=ho_maxprob_atlas_img_resamp,\n",
    "    background_label=0\n",
    ")\n",
    "av_roi_signals = av_roi_data[0]\n",
    "roi_labels = av_roi_data[1]\n",
    "print(\"average_roi_signals is a %s with shape: %s\" % (type(av_roi_signals).__name__, av_roi_signals.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlyLRIgK93tk"
   },
   "source": [
    "### Task: Functional Connectivity Analysis and Visualization\n",
    "\n",
    "#### **What are we doing?**\n",
    "\n",
    "1. **Calculating Functional Connectivity**:\n",
    "   - Using the `ConnectivityMeasure` class with the `kind='correlation'` parameter, we compute the functional connectivity matrix. This matrix represents the correlation between the average signals of different brain regions (ROIs).\n",
    "   - The result is a symmetric matrix where each value indicates the strength of the functional relationship between two regions.\n",
    "\n",
    "2. **Inspecting the Connectivity Matrix**:\n",
    "   - After calculation, we check the shape of the connectivity matrix (`corr_mat`) to ensure it matches the number of ROIs in the atlas.\n",
    "\n",
    "3. **Visualizing the Connectivity Matrix**:\n",
    "   - We use `plotting.plot_matrix` to visualize the connectivity matrix as a heatmap. The `reorder='average'` option reorders the regions based on hierarchical clustering to reveal potential network structures.\n",
    "   - We also adjust the tick label sizes for better readability.\n",
    "\n",
    "4. **Visualizing the Connectome**:\n",
    "   - Using `plotting.view_connectome`, we visualize the connectivity data as a spatial connectome graph. Here:\n",
    "     - **Nodes**: Represent brain regions, located at the center coordinates of the corresponding ROI.\n",
    "     - **Edges**: Represent connections (correlations) between regions, with an edge threshold set to show only the top 5% strongest connections.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why are we doing this?**\n",
    "\n",
    "1. **Understanding Brain Network Dynamics**:\n",
    "   - Functional connectivity captures how different brain regions interact based on synchronized activity. This provides insights into the functional organization of the brain.\n",
    "\n",
    "2. **Revealing Network Structures**:\n",
    "   - Visualizing the connectivity matrix highlights patterns and clusters that may correspond to functional networks (e.g., motor, visual, or default mode networks).\n",
    "\n",
    "3. **Spatial Representation of Connections**:\n",
    "   - The connectome graph allows us to see the spatial relationships of brain region interactions, making it easier to interpret how anatomical proximity relates to functional connectivity.\n",
    "\n",
    "4. **Preparing for Advanced Analyses**:\n",
    "   - Connectivity analysis is a foundation for exploring neurological and psychiatric conditions, comparing group differences, or investigating the impact of interventions.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXZLZlRoeQ3S"
   },
   "source": [
    "Initialize the correlation [ConnectivityMeasure](https://nilearn.github.io/stable/modules/generated/nilearn.connectome.ConnectivityMeasure.html)\n",
    "\n",
    "hint: set the `kind` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFC9HxA0SiXQ"
   },
   "outputs": [],
   "source": [
    "cm = #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rA0zY7lheZfb"
   },
   "source": [
    "Calculate the correlation between average roi signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBQr2KdHSiXR",
    "outputId": "e57f4e53-36e5-40b0-db05-201ea3bd475d"
   },
   "outputs": [],
   "source": [
    "\n",
    "#TO DO\n",
    "corr_mat = #TODO  \n",
    "print(\"corr_mat now has the following shape: %s\" % (corr_mat.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z4JVIKFESiXS",
    "outputId": "8806a39e-9c51-4893-94ff-ebeb1c8bae29"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "display = plotting.plot_matrix(\n",
    "    corr_mat,\n",
    "    labels=ho_maxprob_atlas['labels'][1:],\n",
    "    reorder='average',\n",
    "    figure=fig\n",
    ")\n",
    "\n",
    "# Increase the labels a bit\n",
    "display.axes.tick_params(axis='both', which='major', labelsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmKKP0STeuQw"
   },
   "source": [
    "Use [find_parcellation_cut_coords](https://nilearn.github.io/dev/modules/generated/nilearn.plotting.find_parcellation_cut_coords.html) to get the coords of the center of mass of the atlas regions and visualize the connectivity using  [view_connectome](https://nilearn.github.io/stable/modules/generated/nilearn.plotting.view_connectome.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "9Fw8CeEISiXS",
    "outputId": "342f7757-e096-4da3-c737-36eddac4232f"
   },
   "outputs": [],
   "source": [
    "#TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETiokDGHSiXT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aKXarq593tk"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "<br> Q1: What is the purpose of using plot_epi() in fMRI analysis? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> Q2: Why is image.mean_img() used in preprocessing functional fMRI data? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> Q3: What is the role of smoothing (image.smooth_img) in fMRI analysis? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> Q4: How does the Harvard-Oxford atlas aid in fMRI analysis? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> Q5: What is the significance of resampling the atlas image to match the functional image (image.resample_to_img)? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> Q6: What is the purpose of regions.img_to_signals_labels in fMRI analysis? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "<br> Q7: Why is correlation used in connectivity analysis (ConnectivityMeasure(kind='correlation'))? <br><br> <font color=\"#008000\">Answer:</font>\n",
    "\n",
    "\n",
    "<br> Q8: What are the advantages of thresholding edges in connectivity graphs (e.g., edge_threshold=\"95%\")? <br><br> <font color=\"#008000\">Answer:</font>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
